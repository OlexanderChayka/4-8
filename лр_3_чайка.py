# -*- coding: utf-8 -*-
"""ЛР_3_Чайка

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pw-IJt84lgMX8RxyhlQ47gHAzAPTEyW_

Чайка О.О. був присутнім на уроці.
"""

import seaborn as sns

from google.colab import files
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

import kagglehub
import os

path = kagglehub.dataset_download("prokshitha/home-value-insights")
print("Path to dataset files:", path)

df = pd.read_csv(os.path.join(path, "house_price_regression_dataset.csv"))

df.head()

df.info()

df.duplicated().sum()

df.isnull().sum()

df.describe()

df['Neighborhood_Quality'].value_counts()

sns.countplot(x='Neighborhood_Quality', data=df)
plt.title('Neighborhood_Quality')
plt.show()

df['Num_Bathrooms'].value_counts()

sns.countplot(x='Num_Bathrooms', data=df)
plt.title('Num_Bathrooms')
plt.show()

#sns.pairplot(df)

mtx = df.drop('House_Price', axis=1).corr(numeric_only=True).abs()

fig, ax = plt.subplots(figsize=(8, 8))

sns.heatmap(
    mtx,
    cmap='crest',
    annot=True,
    fmt=".2f",
    linewidths=0.5,
    mask=np.triu(np.ones_like(mtx, dtype=bool)),
    square=True,
    cbar=False,
    ax=ax
)

plt.title('Матриця попарної кореляції ознак', fontsize=14)
plt.tight_layout()
plt.show()

correlation_matrix = df.corr(numeric_only=True)

correlation_with_House_Price = correlation_matrix["House_Price"].sort_values(ascending=False)

correlation_with_House_Price

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error

X = df.drop(columns=['House_Price'])
y = df['House_Price']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

models = {
    "LinearRegression": LinearRegression(),
    "Ridge": Ridge(alpha=1.0),
    "Lasso": Lasso(alpha=0.1),
    'Random Forest': RandomForestRegressor(),
    'Gradient Boosting': GradientBoostingRegressor()
}

results = {}

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)

    r2 = model.score(X_train, y_train)
    mae = mean_absolute_error(y_test, y_pred)
    mse = mean_squared_error(y_test, y_pred)

    results[name] = {
        "model": model,
        "y_pred": y_pred,
        "R²": r2,
        "MAE": mae,
        "MSE": mse
    }

    print(f"[{name}] R²: {r2:.3f} | MAE: {mae:.3f} | MSE: {mse:.3f}")

for name, res in results.items():
    plt.figure(figsize=(6, 4))
    plt.scatter(y_test, res["y_pred"], alpha=0.6, edgecolors='k')
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()],
             'r--', label='Ідеальне передбачення')

    plt.xlabel("Фактична ціна нерухомості")
    plt.ylabel("Передбачена ціна")
    plt.title(f"{name}: фактична vs передбачена")
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

from sklearn.model_selection import GridSearchCV
param_rf = {
    'n_estimators': [50, 100, 200],
    'max_features': ['sqrt', 'log2', None],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10],
}

rf_reg_gs = RandomForestRegressor(random_state=42)
rf_search = GridSearchCV(estimator=rf_reg_gs, param_grid = param_rf, cv=3)
rf_search.fit(X_train, y_train)
best_rf_params = rf_search.best_params_

best_rf_params

rf_optimal = RandomForestRegressor(**best_rf_params, random_state=42)
rf_optimal.fit(X_train, y_train)
y_pred_rf_optimal = rf_optimal.predict(X_test)

# Розрахунки для тестових даних
rf_mse = mean_squared_error(y_test, y_pred_rf_optimal )
rf_mae = mean_absolute_error(y_test, y_pred_rf_optimal )
rf_r2 = r2_score(y_test, y_pred_rf_optimal )

print("MSE:", rf_mse)
print("MAE:", rf_mae)
print("R2:", rf_r2)

"""Висновок: підбір параметрів позитивно вплинув на якість побудови моделі"""

# Отримуємо передбачення для лінійної регресії
linreg_pred = results['LinearRegression']['y_pred']

# Створюємо DataFrame для аналізу
comparison_df = pd.DataFrame({
    "Фактична ціна": y_test.values,
    "Передбачена ціна": linreg_pred,
})

# Обчислюємо похибку у відсотках
comparison_df["Похибка, %"] = (
    np.abs(comparison_df["Передбачена ціна"] - comparison_df["Фактична ціна"])/ comparison_df["Фактична ціна"]
) * 100

# Вибираємо 10 випадкових рядків
sample = comparison_df.sample(10, random_state=42)

# Виводимо результат з округленням до 2 знаків
print(sample.round(2))

"""Висновок: у лабораторній роботі було перевірено датасет, виконано його аналіз та візуалізацію. Побудовано декілька регресійних моделей, проведено оцінку їхньої точності та похибки."""