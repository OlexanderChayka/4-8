# -*- coding: utf-8 -*-
"""Лаб5 Чайка.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cd-eaZTiJVEryMaEhK-bvB8-w7BYhz8A

Чайка О.О. був на парі

Лабораторна робота 5
Класифікація. Запобігання перенавчанню.
Завантажити датасет https://www.kaggle.com/datasets/iammustafatz/diabetes-prediction-dataset?select=diabetes_prediction… Провести попередній аналіз і підготовку даних. Перевірити наявність пропущених даних, дублікатив, попарну кореляцію, кореляцію з цільовою змінною. Перевірити симетричність розподілу, балансування класів. Побудувати моделі models = { 'LogisticRegression': LogisticRegression(), 'RidgeClassifier': RidgeClassifier(), 'SGDClassifier': SGDClassifier(), 'SVC': SVC() }
Вивести класифікаційний звіт, матрицю плутанини. Підібрати оптимальні параметри HalvingGridSearchCV Вивести оптимальні параметри Вивести класифікаційний звіт Вивести 10 випадкових записів з тестової вибірки, справжній і прогнозований клас. Написати висновки.
Попередження про переадресування
"""

from google.colab import files
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import os

import kagglehub

# Download latest version
path = kagglehub.dataset_download("iammustafatz/diabetes-prediction-dataset")

print("Path to dataset files:", path)

df = pd.read_csv(os.path.join(path, "diabetes_prediction_dataset.csv"))
df

df.info()

df.value_counts('gender')

df.value_counts('smoking_history')

df['gender'] = df['gender'].map({'Female': 0, 'Male': 1, 'Other': 2})

df['smoking_history'] = df['smoking_history'].map({'No Info': 0,'never': 1, 'former': 2, 'current': 3, 'not current': 4,'ever': 5})

df

"""gender — стать людини (object; наприклад, male/female).

age — вік (float64).

hypertension — наявність гіпертонії (0 — ні, 1 — так).

heart_disease — наявність серцевого захворювання (0 — ні, 1 — так).

smoking_history — історія куріння (object; наприклад, never, former, current тощо).

bmi — індекс маси тіла (float64).

HbA1c_level — рівень глікозильованого гемоглобіну (float64), важливий показник цукрового діабету.

blood_glucose_level — рівень глюкози в крові (int64).

diabetes — наявність діабету (0 — ні, 1 — так) — цільова змінна.
"""

df.dtypes

df['diabetes'].value_counts()

df.isnull().sum()

df.duplicated().sum()

df.drop_duplicates(inplace=True)

df

df['diabetes'].value_counts()

sns.countplot(x='diabetes', data=df)
plt.title('diabetes')
plt.show()

df.describe()

df.corrwith(df['diabetes']).sort_values(ascending=False)

mtx = df.drop('diabetes', axis=1).corr(numeric_only=True).abs()

fig, ax = plt.subplots(figsize=(8, 8))

sns.heatmap(
    mtx,
    cmap='coolwarm',
    annot=True,
    fmt=".2f",
    linewidths=0.5,
    mask=np.triu(np.ones_like(mtx, dtype=bool)),
    square=True,
    cbar=False,
    ax=ax
)

plt.title('Матриця попарної кореляції ознак', fontsize=14)
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 6))
sns.boxplot(data=df)
plt.xticks(rotation=45)
plt.title("Boxplot for numeric columns")
plt.show()

"""Мають багато викидив але видаляти їх недоцільно"""

df.skew(numeric_only=True)

df.isnull().sum()

from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier
from sklearn.svm import SVC

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import  precision_score, recall_score, f1_score

from sklearn.metrics import classification_report, confusion_matrix
from imblearn.over_sampling import SMOTE

X = df.drop("diabetes", axis=1)
y = df["diabetes"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

smote = SMOTE(random_state=42)
X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)

print("До балансування:")
print(y_train.value_counts())
print("\nПісля SMOTE:")
print(y_train_balanced.value_counts())

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

models = {
    'LogisticRegression': LogisticRegression(),
    'RidgeClassifier': RidgeClassifier(),
    'SGDClassifier': SGDClassifier(),
    'SVC': SVC()
}

# Тренуємо, оцінюємо й виводимо звіти
for name, model in models.items():
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)

    print(f"\n=== {name} ===")
    print(classification_report(y_test, predictions))

    # Матриця плутанини
    cm = confusion_matrix(y_test, predictions)
    plt.figure(figsize=(5, 4))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.title(f'Confusion Matrix - {name}')
    plt.xlabel('Predicted')
    plt.ylabel('Actual')
    plt.tight_layout()
    plt.show()

param_grids = {
    'LogisticRegression': {
        'C': [0.01, 0.1, 1, 10],
        'solver': ['lbfgs', 'liblinear']
    },
    'RidgeClassifier': {
        'alpha': [0.1, 1.0, 10.0]
    },
    'SGDClassifier': {
        'loss': ['log_loss', 'hinge'],
        'alpha': [0.0001, 0.001, 0.01],
        'penalty': ['l2', 'l1']
    },
    'SVC': {
        'C': [0.1, 1, 10],
        'kernel': ['linear', 'rbf']
    }
}

from sklearn.model_selection import HalvingGridSearchCV

best_models = {}

# Перебір моделей
for name, model in models.items():
    print(f"\n Підбір параметрів для {name}...")

    search = HalvingGridSearchCV(
        estimator=model,
        param_grid=param_grids[name],
        scoring='accuracy',
        cv=3,
        factor=2,
        random_state=42,
        n_jobs=-1
    )

    search.fit(X_train, y_train)
    best_model = search.best_estimator_
    best_models[name] = best_model

    print(f" Найкращі параметри: {search.best_params_}")

    # Оцінка
    y_pred = best_model.predict(X_test)
    print("Класифікаційний звіт:")
    print(classification_report(y_test, y_pred))

best_svc = best_models["SVC"]

# Вибір 10 випадкових індексів
random_indices = np.random.choice(X_test.shape[0], 20, replace=False)

# Отримання прогнозованих значень від найкращої моделі SVC
y_pred_best_svc = best_svc.predict(X_test)

# Порівняння справжніх і прогнозованих значень для вибраних випадкових індексів
random_results_df = pd.DataFrame({
    'Index': random_indices,
    'True Values': y_test.iloc[random_indices].values,  # Справжні значення
    'Predicted Values': y_pred_best_svc[random_indices]  # Прогнозовані значення
})

random_results_df

"""Висновок:у ході лабораторної роботи було проведено повний цикл побудови моделей класифікації. Було перевірено наявність пропущених значень, дублікатів, кореляції між ознаками та балансування класів. Після попереднього аналізу було навчено кілька моделей і здійснено підбір оптимальних параметрів."""